{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "awful-clear",
   "metadata": {},
   "source": [
    "# Multiprocessng Federated MNIST torch Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-accent",
   "metadata": {},
   "source": [
    "## !!WARNING!! \n",
    "Multiprocessing is not stable in Jupyter Notebook. Some processes can live in the memory when the main already finished.\n",
    "We recomended to restart the kernel after every experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-credit",
   "metadata": {},
   "source": [
    "To run federation in multiprocessing way you need: \n",
    "1. define model class `Net`, and functions thats return opimizer `get_optimizer` and loss function `cross_entropy` in **in separate cell**. \n",
    "2. save jupyter notebook cell as file using `%%writefile <filename>` in the top of the cell.\n",
    "2. import `Net`, `cross_entropy` and `get_optimizer` in the next cell\n",
    "   from <filename> import Net, cross_entropy, get_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-pierre",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile torch_model.py\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"PyTorch Neural Network.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 32)\n",
    "        self.fc2 = nn.Linear(32, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the network.\"\"\"\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def cross_entropy(output, target):\n",
    "    \"\"\"Binary cross-entropy metric.\"\"\"\n",
    "    return F.cross_entropy(input=output, target=target)\n",
    "\n",
    "\n",
    "def get_optimizer(x):\n",
    "    \"\"\"Optimizer function.\"\"\"\n",
    "    return optim.Adam(x, lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-medicine",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openfl torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround to run multiprocessing scenario in Jupyter Notebook\n",
    "# Don't define those instances in this cell directily\n",
    "from torch_model import Net, cross_entropy, get_optimizer\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import openfl.native as fx\n",
    "from openfl.federated import FederatedModel, FederatedDataSet\n",
    "from openfl.interface.cli import setup_logging\n",
    "\n",
    "\n",
    "def one_hot(labels, classes):\n",
    "    \"\"\"One-hot encode `labels` using `classes` classes.\"\"\"\n",
    "    return np.eye(classes)[labels]\n",
    "\n",
    "\n",
    "setup_logging()\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "fx.init('torch_cnn_mnist')\n",
    "\n",
    "is_multi = True\n",
    "batch_size = 32\n",
    "rounds_to_train = 2\n",
    "collaborators_amount = 5\n",
    "classes = 10\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "trainset = datasets.MNIST(root='./data',\n",
    "                          train=True,\n",
    "                          download=True,\n",
    "                          transform=transform)\n",
    "\n",
    "validset = datasets.MNIST(root='./data',\n",
    "                          train=False,\n",
    "                          download=True,\n",
    "                          transform=transform,\n",
    "                          target_transform=lambda labels: one_hot(labels, classes))\n",
    "\n",
    "(train_images, train_labels), (valid_images, valid_labels) = (zip(*dataset) for dataset in\n",
    "                                                              [trainset, validset])\n",
    "train_images, valid_images = (torch.stack(images).numpy() for images in\n",
    "                              [train_images, valid_images])\n",
    "train_labels, valid_labels = (np.stack(labels) for labels in [train_labels, valid_labels])\n",
    "feature_shape = train_images.shape[1]\n",
    "\n",
    "fl_data = FederatedDataSet(train_images, train_labels, valid_images, valid_labels,\n",
    "                           batch_size=batch_size, num_classes=classes)\n",
    "fl_model = FederatedModel(build_model=Net, optimizer=get_optimizer,\n",
    "                          loss_fn=cross_entropy, data_loader=fl_data)\n",
    "collaborator_models = fl_model.setup(num_collaborators=collaborators_amount)\n",
    "collaborators = {str(i): c for i, c in enumerate(collaborator_models)}\n",
    "\n",
    "print(f'Original training data size: {len(train_images)}')\n",
    "print(f'Original validation data size: {len(valid_images)}\\n')\n",
    "\n",
    "final_fl_model = fx.run_experiment(collaborators, {\n",
    "    'aggregator.settings.rounds_to_train': rounds_to_train,\n",
    "}, is_multi=is_multi)\n",
    "final_fl_model.save_native('final_pytorch_model')\n",
    "print(f'FINISH in {(time.time() - t):.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-korea",
   "metadata": {},
   "source": [
    "## !!NOTICE!!  Don't forget to reload kernel after execution\n",
    "<img align=\"left\" src=\"reload_kernel.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}